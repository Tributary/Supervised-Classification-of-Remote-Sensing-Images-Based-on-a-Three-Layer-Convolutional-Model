import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import cv2
import os

class RemoteSensingCNN(nn.Module):
    def __init__(self, num_classes=21):
        super(RemoteSensingCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            # ç¬¬ä¸€ä¸ªå·ç§¯å—
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2),
            nn.Dropout(0.25),
            
            # ç¬¬äºŒä¸ªå·ç§¯å—
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(2),
            nn.Dropout(0.25),
            
            # ç¬¬ä¸‰ä¸ªå·ç§¯å—
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128),
            nn.MaxPool2d(2),
            nn.Dropout(0.25),
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(128 * 8 * 8, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

class SlidingWindowPredictor:
    def __init__(self, model_path='best_remote_sensing_model.pth'):
        
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        
        # ä¿®å¤å®‰å…¨è­¦å‘Šï¼šå…ˆå°è¯•å®‰å…¨æ¨¡å¼ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼
        try:
            # å°è¯•ä½¿ç”¨å®‰å…¨æ¨¡å¼åŠ è½½
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=True)
            print("âœ… ä½¿ç”¨å®‰å…¨æ¨¡å¼åŠ è½½æ¨¡å‹")
        except Exception as e:
            # å¦‚æœå®‰å…¨æ¨¡å¼å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼
            print("âš ï¸ å®‰å…¨æ¨¡å¼åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        
        self.class_names = checkpoint['class_names']
        self.num_classes = len(self.class_names)
        
        print(f"ğŸ“Š åŠ è½½æ¨¡å‹ä¿¡æ¯:")
        print(f"   - ç±»åˆ«æ•°é‡: {self.num_classes}")
        print(f"   - æœ€ä½³å‡†ç¡®ç‡: {checkpoint.get('best_acc', 'N/A')}%")
        print(f"   - å¯è¯†åˆ«ç±»åˆ«: {', '.join(self.class_names)}")
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶åŠ è½½æƒé‡
        self.model = RemoteSensingCNN(num_classes=self.num_classes)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        # é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize((64, 64)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    
    def sliding_window(self, image, window_size=256, stride=128):
        """æ»‘åŠ¨çª—å£ç”Ÿæˆå™¨"""
        h, w = image.shape[:2]
        
        for y in range(0, h - window_size + 1, stride):
            for x in range(0, w - window_size + 1, stride):
                yield (x, y, image[y:y+window_size, x:x+window_size])
    
    def predict_single_window(self, window_image):
        """å¯¹å•ä¸ªçª—å£è¿›è¡Œé¢„æµ‹"""
        # è½¬æ¢çª—å£ä¸ºPILå›¾åƒ
        window_pil = Image.fromarray(window_image)
        
        # é¢„å¤„ç†
        input_tensor = self.transform(window_pil).unsqueeze(0)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted_idx = torch.max(probabilities, 1)
            
            confidence = confidence.item()
            predicted_class = self.class_names[predicted_idx.item()]
            
            return predicted_class, confidence
    
    def predict_big_image(self, big_image_path, window_size=256, stride=128, confidence_threshold=0.5):
        if not os.path.exists(big_image_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶: {big_image_path}")
        
        # è¯»å–å¤§å›¾ç‰‡
        big_image = cv2.imread(big_image_path)
        if big_image is None:
            raise ValueError(f"âŒ æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶: {big_image_path}")
        
        big_image = cv2.cvtColor(big_image, cv2.COLOR_BGR2RGB)
        h, w = big_image.shape[:2]
        
        print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {w} Ã— {h}")
        print(f"ğŸªŸ çª—å£å¤§å°: {window_size} Ã— {window_size}")
        print(f"ğŸš¶ æ»‘åŠ¨æ­¥é•¿: {stride}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦é˜ˆå€¼: {confidence_threshold}")
        
        # å¦‚æœå›¾ç‰‡å¤ªå°ï¼Œè°ƒæ•´çª—å£å¤§å°
        if h < window_size or w < window_size:
            print("âš ï¸ å›¾ç‰‡å°ºå¯¸è¾ƒå°ï¼Œè‡ªåŠ¨è°ƒæ•´çª—å£å¤§å°")
            window_size = min(h, w) // 2
            stride = window_size // 2
        
        # å­˜å‚¨è¯†åˆ«ç»“æœ
        results = []
        window_count = 0
        
        print("â³ æ­£åœ¨åˆ†æå›¾ç‰‡åŒºåŸŸ...")
        # æ»‘åŠ¨çª—å£å¤„ç†
        for x, y, window in self.sliding_window(big_image, window_size, stride):
            window_count += 1
            
            # å¯¹å½“å‰çª—å£è¿›è¡Œé¢„æµ‹
            predicted_class, confidence = self.predict_single_window(window)
            
            # åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„ç»“æœ
            if confidence > confidence_threshold:
                results.append({
                    'x': x, 'y': y, 
                    'class': predicted_class,
                    'confidence': confidence,
                    'window_size': window_size
                })
            
            # æ˜¾ç¤ºè¿›åº¦
            if window_count % 10 == 0:
                print(f"  å·²å¤„ç† {window_count} ä¸ªçª—å£ï¼Œæ‰¾åˆ° {len(results)} ä¸ªé«˜ç½®ä¿¡åº¦åŒºåŸŸ")
        
        print(f"âœ… å¤„ç†å®Œæˆï¼å…±åˆ†æ {window_count} ä¸ªçª—å£ï¼Œæ‰¾åˆ° {len(results)} ä¸ªé«˜ç½®ä¿¡åº¦åŒºåŸŸ")
        return results, big_image, window_count
    
    def visualize_results(self, big_image, results, window_size=256, output_path='result/result.png'):
        """å¯è§†åŒ–è¯†åˆ«ç»“æœ"""
        if len(results) == 0:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•é«˜ç½®ä¿¡åº¦çš„åŒºåŸŸ")
            print("ğŸ’¡ å»ºè®®: é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–æ£€æŸ¥å›¾ç‰‡å†…å®¹")
            return None
        
        plt.figure(figsize=(15, 10))
        
        # åˆ›å»ºé¢œè‰²æ˜ å°„
        colors = plt.cm.Set3(np.linspace(0, 1, len(self.class_names)))
        color_map = {cls: colors[i] for i, cls in enumerate(self.class_names)}
        
        # æ˜¾ç¤ºåŸå›¾
        plt.imshow(big_image)
        plt.title('å¤§å›¾ç‰‡åŒºåŸŸè¯†åˆ«ç»“æœ', fontsize=16, fontweight='bold')
        
        # ç»˜åˆ¶è¯†åˆ«æ¡†
        for result in results:
            x, y = result['x'], result['y']
            class_name = result['class']
            confidence = result['confidence']
            
            # ç»˜åˆ¶çŸ©å½¢æ¡†
            rect = Rectangle((x, y), window_size, window_size, 
                           linewidth=2, edgecolor=color_map[class_name], 
                           facecolor='none', alpha=0.8)
            plt.gca().add_patch(rect)
            
            # æ·»åŠ æ ‡ç­¾
            plt.text(x + 5, y + 15, f'{class_name}\n({confidence:.2f})', 
                    fontsize=8, color=color_map[class_name], fontweight='bold',
                    bbox=dict(boxstyle="round,pad=0.3", facecolor='white', alpha=0.9))
        
        plt.axis('off')
        plt.tight_layout()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # ä¿å­˜ç»“æœå›¾ç‰‡
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾åƒä»¥é¿å…å†…å­˜æ³„æ¼
        print(f"ğŸ“¸ ç»“æœå›¾å·²ä¿å­˜ä¸º: {output_path}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(results, output_path.replace('.png', '_report.txt'))
        
        return output_path
    
    def generate_report(self, results, report_path):
        """ç”Ÿæˆè¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š"""
        from collections import Counter
        
        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        class_counter = Counter([r['class'] for r in results])
        total_regions = len(results)
        
        print("\nğŸ“ˆ åŒºåŸŸè¯†åˆ«ç»Ÿè®¡æŠ¥å‘Š:")
        print("=" * 50)
        for cls, count in class_counter.most_common():
            percentage = (count / total_regions) * 100
            print(f"  {cls:<20}: {count:>3} ä¸ªåŒºåŸŸ ({percentage:>5.1f}%)")
        
        print(f"  æ€»è®¡: {total_regions} ä¸ªè¯†åˆ«åŒºåŸŸ")
        print("=" * 50)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("åŒºåŸŸè¯†åˆ«ç»Ÿè®¡æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            for cls, count in class_counter.most_common():
                percentage = (count / total_regions) * 100
                f.write(f"{cls:<20}: {count:>3} ä¸ªåŒºåŸŸ ({percentage:>5.1f}%)\n")
            f.write(f"æ€»è®¡: {total_regions} ä¸ªè¯†åˆ«åŒºåŸŸ\n")
        
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜ä¸º: {report_path}")

def batch_predict_images():
    WINDOW_SIZE =256       # çª—å£å¤§å°
    STRIDE = 128           # æ»‘åŠ¨æ­¥é•¿  
    CONFIDENCE_THRESHOLD = 0.7
    model_path = 'best_remote_sensing_model.pth'
    test_dir = 'test'
    result_dir = 'result'
    os.makedirs(result_dir, exist_ok=True)
    predictor = SlidingWindowPredictor(model_path)
    image_files = [f for f in os.listdir(test_dir) if f.lower().endswith('.png')]
    image_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
    
    for i, image_file in enumerate(image_files, 1):# æ‰¹å¤„ç†
        image_path = os.path.join(test_dir, image_file)
        image_name = os.path.splitext(image_file)[0]  # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        
        print(f"\n[{i}/{len(image_files)}] å¤„ç†å›¾ç‰‡: {image_file}")
        
        try:
            # è¿›è¡Œé¢„æµ‹
            results, big_image, total_windows = predictor.predict_big_image(
                image_path, 
                window_size=WINDOW_SIZE, 
                stride=STRIDE, 
                confidence_threshold=CONFIDENCE_THRESHOLD
            )
            
            # ä¿å­˜ç»“æœ
            output_path = os.path.join(result_dir, f"{image_name}_result.png")
            predictor.visualize_results(big_image, results, WINDOW_SIZE, output_path)
            
            print(f"âœ… å›¾ç‰‡ {image_file} å¤„ç†å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾ç‰‡ {image_file} æ—¶å‡ºé”™: {e}")
            continue
    
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {result_dir} æ–‡ä»¶å¤¹")

if __name__ == '__main__':
    batch_predict_images()